{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a simple tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1709, 0.8422],\n",
       "        [0.6398, 0.0631],\n",
       "        [0.6261, 0.9506]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.ones(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1709, 1.8422],\n",
       "        [1.6398, 1.0631],\n",
       "        [1.6261, 1.9506]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torchvision contains some datasets. Here we will be using the MNIST dataset. Bunch of images of hand-drawn images 0-9. This dataset is used to train a network or other machine learning algorithms such that they can classify the images into those digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    \n",
    "    # need to provide the forward function\n",
    "    # x is the input tensor\n",
    "    # goal here is to pass this tensor to each of the above defined layers.\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        # need to dim=1 because first dim is the batch size, which is 64 in this case\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0008,  0.0113,  0.0005,  ..., -0.0103,  0.0154, -0.0169],\n",
      "        [-0.0025,  0.0268, -0.0347,  ..., -0.0218,  0.0259, -0.0130],\n",
      "        [ 0.0052,  0.0199,  0.0124,  ...,  0.0337,  0.0078, -0.0096],\n",
      "        ...,\n",
      "        [ 0.0056, -0.0210, -0.0255,  ...,  0.0275,  0.0044, -0.0192],\n",
      "        [-0.0150,  0.0284,  0.0178,  ...,  0.0148, -0.0187,  0.0054],\n",
      "        [ 0.0122,  0.0119, -0.0173,  ..., -0.0242, -0.0032, -0.0032]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# The weights and baises are automatically set when you define the network like above.\n",
    "print(model.fc1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0166,  0.0107, -0.0272, -0.0004,  0.0211, -0.0336, -0.0112, -0.0095,\n",
      "        -0.0125,  0.0012, -0.0334,  0.0260, -0.0305, -0.0145, -0.0265, -0.0266,\n",
      "        -0.0053, -0.0338, -0.0150,  0.0073, -0.0270,  0.0174,  0.0171,  0.0345,\n",
      "        -0.0176,  0.0192, -0.0022,  0.0061, -0.0272,  0.0264, -0.0068, -0.0141,\n",
      "        -0.0089, -0.0013, -0.0042, -0.0227, -0.0134, -0.0247, -0.0084, -0.0256,\n",
      "        -0.0352,  0.0315,  0.0178, -0.0017, -0.0239,  0.0181,  0.0100,  0.0209,\n",
      "        -0.0137,  0.0353, -0.0173,  0.0076, -0.0336, -0.0189,  0.0206,  0.0008,\n",
      "         0.0083,  0.0096, -0.0228, -0.0248,  0.0127,  0.0231, -0.0218,  0.0235,\n",
      "        -0.0332,  0.0228,  0.0045,  0.0296,  0.0305, -0.0028, -0.0270,  0.0173,\n",
      "        -0.0035, -0.0084,  0.0018,  0.0209, -0.0037, -0.0009, -0.0223,  0.0112,\n",
      "        -0.0062, -0.0185, -0.0020,  0.0130,  0.0266,  0.0097,  0.0094,  0.0242,\n",
      "        -0.0275, -0.0087,  0.0052, -0.0233, -0.0080,  0.0199,  0.0071, -0.0070,\n",
      "         0.0304, -0.0261,  0.0255, -0.0019, -0.0248,  0.0174,  0.0260,  0.0269,\n",
      "        -0.0277, -0.0168, -0.0058,  0.0229, -0.0146, -0.0200,  0.0259,  0.0191,\n",
      "        -0.0326, -0.0342, -0.0093, -0.0107, -0.0174, -0.0285, -0.0037, -0.0253,\n",
      "         0.0098,  0.0138,  0.0244, -0.0129, -0.0280, -0.0327,  0.0312,  0.0006],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.bias.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
